---
title: "Project 4: A Music Recommendation System with Social Context"
author: James Hamski (james.hamski@spsmail.cuny.edu), Vuthy Nguy (vuthy.nguy@spsmail.cuny.edu)
date: "July 10, 2016"
output:
  pdf_document:
    fig_caption: no
    keep_tex: no
    number_sections: yes
  html_document:
    fig_caption: no
    force_captions: yes
    highlight: pygments
    number_sections: yes
    theme: cerulean
csl: report_formatting.csl
---

```{r, warning=FALSE, message=FALSE, error=TRUE}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(knitr)
library(igraph)
```

# User-Artist Data

Reading in needed datasets. Artist information will be joined to user-artist dataset for readability
```{r Read_Dataset, cache=TRUE, warnings = FALSE}
user.artists.pairwise <- read_delim('hetrec2011-lastfm-2k/user_artists.dat', delim = "\t")

artists <- read_delim('hetrec2011-lastfm-2k/artists.dat', delim = "\t") %>% select(id, name)
```

##Data Preparation

Converting from Artist IDs to Artist Names for easier interpretation.
```{r join_artist_name, cache=TRUE}
colnames(artists) <- c("artistID", "name")

#note: one duplicate artist
#artists$name[duplicated(artists$name)==TRUE]
user.artists.pairwise <- inner_join(user.artists.pairwise, artists, by="artistID")

user.artists.pairwise <- select(user.artists.pairwise, -artistID)

user.artists.pairwise$name <- strtrim(user.artists.pairwise$name, 100)

user.artists.pairwise[16060,]$name <- NA

#ggplot(user.artists.pairwise, aes(x = weight)) + geom_density() + theme_bw() + scale_x_log10()
```

The user-artist pairwise record contains multiple rows for a single artist. In order to understand the distribution of listens for artists, we group and sum for each artist. 
```{r}
artist.listens <- user.artists.pairwise %>%
  group_by(name) %>% 
  summarise(total.listens = sum(weight))
```


## Exploratory Data Analysis

The median number for listens is 324 - quite  a low number! The highest number of listens is Britney Spears with 2.3 million listens. We believe this dataset could be well modeled with a lognormal distribution. 
```{r}
summary(artist.listens$total.listens)
ggplot(artist.listens, aes(x = total.listens)) + geom_density() + theme_bw() + scale_x_log10()
```

Looking at the top 10 artists it is important to note that Britney Spears has nearly twice as many listens as the next most popular artist, Depeche Mode. 
```{r}
artist.listens %>% arrange(desc(total.listens)) %>% top_n(10) %>% kable()
```

We have decided to limit our recommender system to artist who have more than 900 total listens.
```{r}
listens.cutoff <- 900
artist.cutoff <- artist.listens %>% filter(total.listens >= listens.cutoff)
```

## User-Item Matrix Construction
Using the TidyR library the pairwise data was converted into a sparse matrix.
```{r spread_data, cache=TRUE}
user.artists.matrix <- user.artists.pairwise %>%
  filter(name %in% artist.cutoff$name) %>% #filter artists with less than num_listens listens
  spread(key = name, value = weight) %>%
  distinct() %>%
  as.matrix()

rownames(user.artists.matrix) <- user.artists.matrix[,1]
user.artists <- user.artists.matrix[,-1]
dim(user.artists)
```

### Filtering out artists with less than 0.5% of the users listening to them
```{r}
#Number of listeners cutoff rate: 0.5%
cutoff.rate <- 0.005

#Calculate cutoff numbner
n.users <- nrow(user.artists.matrix)
n.user.cutoff <- round(cutoff.rate * n.users)

#Empty vector to store counts
listener.count <- vector()

#For each artist, sum up number of users who listened to them
for (n in 2:ncol(user.artists.matrix)) {
  counts <- sum(!is.na(user.artists.matrix[,n]))
  listener.count <- c(listener.count, counts)
}

#Create logical vector for artists with less listeners than cutoff rate
listener.bool <- listener.count > n.user.cutoff

#Remove artists that didnt meet cutoff
mtx.cutoff <- user.artists.matrix[,listener.bool]

dim(user.artists.matrix)
dim(mtx.cutoff)

#new user.artists.matrix with
user.artists <- mtx.cutoff

```

### Dealing with NAs

We tried two ways of dealing with NAs - imputing with column averages, and replacing with 0s.Note that due to the sparsity of the dataset, for most artists the column mean rounds to zero. In addition, the dataframe with column means was centered and scaled around 0 using the scale function. This gives us two views of the same dataset- one with NAs replaced with zeros which is relatively unmodified, and another with column means replacing NAs and normalized listen counts. 
```{r}
# http://stackoverflow.com/questions/25835643/replacing-missing-values-in-r-with-column-mean
user.artists.ave <- user.artists
for(i in 1:ncol(user.artists.ave)){
  user.artists.ave[is.na(user.artists.ave[,i]), i] <- mean(user.artists.ave[,i], na.rm = TRUE)
}

user.artists.ave <- scale(user.artists.ave)

user.artists[is.na(user.artists)] <- 0
```


# Social Network Data

```{r}
user.friends <- read_delim('hetrec2011-lastfm-2k/user_friends.dat', delim = "\t")
```

```{r}
user.friends$friend <- 1
user.friends.matrix <- user.friends %>% spread(key = userID, value = friend)
user.friends.matrix[is.na(user.friends.matrix)] <- 0

rownames(user.friends.matrix) <- user.friends.matrix$friendID
user.friends.matrix <- user.friends.matrix[,-1]
dim(user.friends.matrix)
```

```{r}
user.graph <- graph.adjacency(as.matrix(user.friends.matrix), mode = "undirected")

#plot(user.graph)
```

## Graph Analysis
The proportion of present edges from all possible edges in the network.
```{r}
edge_density(user.graph)

```
A network diameter is the longest geodesic distance (length of the shortest path between two nodes) in the network.
```{r}
diameter(user.graph)
```

```{r}
# http://kateto.net/networks-r-igraph
deg <- degree(user.graph, mode="all")
#plot(user.graph, vertex.size=deg*3)
hist(deg, breaks=1:vcount(user.graph)-1, main="Histogram of node degree")
```

```{r}
deg.dist <- degree_distribution(user.graph, cumulative=T, mode="all")
plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, xlab="Degree", ylab="Cumulative Frequency")
```

```{r}
mean_distance(user.graph, directed=F)
```

### Communities

```{r}
#cliques(user.graph) # list of cliques       
#sapply(cliques(user.graph), length) # clique sizes
largest_cliques(user.graph) # cliques with max number of nodes
```

```{r, eval=FALSE}
ceb <- cluster_edge_betweenness(user.graph) 
plot(ceb, user.graph) 
```

